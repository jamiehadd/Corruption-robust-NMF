{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNzIczqzonhX"
      },
      "source": [
        "# Quantile Multiplicative Updates for Corruption-Robust Nonnegative Matrix Factorization\n",
        "\n",
        "This notebook is the code appendix for our submission to SampTA 2025."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6G3shzbqr7"
      },
      "source": [
        "# Data\n",
        "\n",
        "The following code was used to generate and corrupt swimmer and synthetic data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRPiOSYQbyMo"
      },
      "source": [
        "## Corrupt Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\lukex\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy\n",
            "  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\lukex\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (2.2.3)\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.15.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy\n",
        "! pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U4SIHSTubx_a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def corrupt_matrix(D_tilde, beta=0.1, corruption_scale=1e6):\n",
        "    \"\"\"\n",
        "    Generates a corrupted data matrix D from an uncorrupted data matrix D_tilde.\n",
        "\n",
        "    This function simulates corruption by adding noise to a fraction of the entries in D_tilde.\n",
        "    The observed data is given by:\n",
        "        D = D_tilde + C,\n",
        "    where C is a sparse corruption matrix. A fraction beta of the entries in D_tilde\n",
        "    are corrupted by adding noise drawn from the absolute value of a Gaussian distribution,\n",
        "    i.e., |N(0, corruption_scale^2)|, ensuring nonnegative noise.\n",
        "\n",
        "    Parameters:\n",
        "        D_tilde (np.ndarray): The original, uncorrupted data matrix.\n",
        "        beta (float): The fraction of entries to corrupt (0 < beta < 1).\n",
        "        corruption_scale (float): The standard deviation of the noise, determining the magnitude of corruption.\n",
        "\n",
        "    Returns:\n",
        "        D (np.ndarray): The corrupted data matrix.\n",
        "    \"\"\"\n",
        "    m, n = D_tilde.shape\n",
        "    total_elements = m * n\n",
        "    num_corrupted = int(total_elements * beta)\n",
        "\n",
        "    # Generate nonnegative noise: absolute value of a Gaussian random variable\n",
        "    noise = np.abs(corruption_scale * np.random.randn(num_corrupted))\n",
        "\n",
        "    # Create a copy of D_tilde and flatten it for easier indexing\n",
        "    D_flat = D_tilde.copy().flatten()\n",
        "\n",
        "    # Randomly select indices to corrupt\n",
        "    corrupt_indices = np.random.choice(total_elements, size=num_corrupted, replace=False)\n",
        "\n",
        "    # Add noise to the selected entries\n",
        "    D_flat[corrupt_indices] += noise\n",
        "\n",
        "    # Reshape back to the original matrix shape\n",
        "    D = D_flat.reshape(m, n)\n",
        "\n",
        "    return D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw0r0lVEv1Uj"
      },
      "source": [
        "## Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rQ8m7ubhe0tO"
      },
      "outputs": [],
      "source": [
        "def generate_synthetic_matrix(m, n, r, beta=0, corruption_scale=1e6):\n",
        "    \"\"\"\n",
        "    Generates a synthetic data matrix D_tilde that is exactly factorizable as\n",
        "        D_tilde = W_tilde @ H_tilde,\n",
        "    where W_tilde and H_tilde have nonnegative integer entries drawn uniformly from {0, ..., 99}.\n",
        "\n",
        "    Parameters:\n",
        "        m (int): Number of rows in D_tilde.\n",
        "        n (int): Number of columns in D_tilde.\n",
        "        r (int): Target rank (latent dimensionality) of the factorization.\n",
        "        beta (float): Proportion of matrix entries to be corrupted.\n",
        "        corruption_scale (float): Size of corruptions to be added.\n",
        "\n",
        "    Returns:\n",
        "        D_tilde (np.ndarray): The uncorrupted synthetic data matrix.\n",
        "        W_tilde (np.ndarray): The ground-truth dictionary matrix.\n",
        "        H_tilde (np.ndarray): The ground-truth representation matrix.\n",
        "    \"\"\"\n",
        "    # Generate factor matrices using the paper's notation.\n",
        "    W_tilde = np.abs(np.random.randint(0, high=100, size=(m, r)))\n",
        "    H_tilde = np.abs(np.random.randint(0, high=100, size=(r, n)))\n",
        "\n",
        "    # Form the uncorrupted data matrix D_tilde.\n",
        "    D_tilde = W_tilde @ H_tilde\n",
        "    D_tilde = D_tilde.astype(float)  # Convert to float to allow for future noise addition\n",
        "\n",
        "    D = D_tilde\n",
        "    if beta > 0:\n",
        "        D = corrupt_matrix(D_tilde, beta, corruption_scale=corruption_scale)\n",
        "\n",
        "    return D, D_tilde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D048xkeffgUG"
      },
      "source": [
        "## Swimmer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NUqremNX1RIU"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def load_swimmer_dataset(beta=0, corruption_scale=1e6, display=False):\n",
        "    \"\"\"\n",
        "    Loads the Swimmer dataset from the 'Swimmer.mat' file.\n",
        "    Ensure 'Swimmer.mat' is in the working directory before calling.\n",
        "\n",
        "    In the .mat file, the data is stored under the key 'X'. Optionally, two sample images\n",
        "    (images 17 and 170) can be displayed.\n",
        "\n",
        "    Parameters:\n",
        "        beta (float): Proportion of matrix entries to be corrupted\n",
        "        corruption_scale (float): Size of corruptions to be added\n",
        "          display (bool): If True, displays two sample images from the dataset.\n",
        "\n",
        "    Returns:\n",
        "        D (np.ndarray): The data matrix from the Swimmer dataset, with corruptions.\n",
        "        D_tilde (np.ndarray): The data matrix from the Swimmer dataset.\n",
        "    \"\"\"\n",
        "    mat = scipy.io.loadmat(\"Swimmer.mat\")\n",
        "    D_tilde = mat['X'].astype(float)\n",
        "    D = D_tilde\n",
        "\n",
        "    if beta > 0:\n",
        "        D = corrupt_matrix(D_tilde, beta, corruption_scale=corruption_scale)\n",
        "\n",
        "    if display:\n",
        "        pic17 = np.reshape(D_tilde[:, 17], (11, 20))\n",
        "        pic170 = np.reshape(D_tilde[:, 170], (11, 20))\n",
        "\n",
        "        plt.figure(figsize=[15, 6])\n",
        "        plt.suptitle(\"Swimmer Images\")\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(pic17)\n",
        "        plt.title(\"Image 17\")\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(pic170)\n",
        "        plt.title(\"Image 170\")\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "    return D, D_tilde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou8tNXrxwwZL"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MQ43KCDmcXzF"
      },
      "outputs": [],
      "source": [
        "# Import our algorithms\n",
        "from nmf import nmf\n",
        "from qmu import qmu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7BOOI3cIJNN"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "3u4poA_3Ya-d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "# Install LaTeX for plotting\n",
        "!sudo apt install -y cm-super dvipng texlive-latex-extra texlive-latex-recommended > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WJmCehGSPicZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def plot_experiment(errors, log_y_axis=False, y_lab=r\"\\text{Relative Error} $\\displaystyle\\frac{\\lVert \\tilde{D} - WH \\rVert}{\\lVert \\tilde{D} \\rVert}$\"):\n",
        "    \"\"\"\n",
        "    Plots the evolution of relative error over iterations for multiple experiments.\n",
        "\n",
        "    Parameters:\n",
        "        errors (dict): Dictionary mapping method labels (str) to numpy arrays of shape\n",
        "                       (num_runs, num_iterations+1) containing relative error values.\n",
        "        log_y_axis (bool): If True, sets the y-axis to a logarithmic scale.\n",
        "        y_lab (str): Label for the y-axis (supports LaTeX formatting).\n",
        "    \"\"\"\n",
        "    plt.style.use('ggplot')\n",
        "    plt.rcParams[\"figure.figsize\"] = (19, 11)\n",
        "    plt.rcParams[\"font.size\"] = 32\n",
        "    plt.rcParams[\"xtick.color\"] = 'black'\n",
        "    plt.rcParams[\"ytick.color\"] = 'black'\n",
        "    plt.rcParams[\"axes.edgecolor\"] = 'black'\n",
        "    plt.rcParams[\"axes.linewidth\"] = 1\n",
        "    plt.rcParams['text.usetex'] = True\n",
        "    plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
        "\n",
        "    labels = list(errors.keys())\n",
        "    num_iterations = errors[labels[0]].shape[1]\n",
        "    domain = range(num_iterations)\n",
        "\n",
        "    dashes = [\n",
        "        [1, 0],      # Solid\n",
        "        [6, 2],      # Dashed\n",
        "        [1, 2],      # Dotted\n",
        "        [4, 2, 1, 2],# Dash-Dot\n",
        "        [8, 2, 2, 2],# Custom\n",
        "        [3, 1, 1, 1]\n",
        "    ]\n",
        "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'teal', 'yellow', 'pink']\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        data_matrix = errors[label]\n",
        "        mean_error = np.mean(data_matrix, axis=0)\n",
        "        min_error = np.min(data_matrix, axis=0)\n",
        "        max_error = np.max(data_matrix, axis=0)\n",
        "\n",
        "        plt.plot(domain, mean_error, label=label, color=colors[i], dashes=dashes[i], linewidth=3)\n",
        "        plt.fill_between(domain, min_error, max_error, color=colors[i], alpha=0.2)\n",
        "\n",
        "    plt.xlabel(\"Iteration\", color='black')\n",
        "    plt.ylabel(y_lab, color='black')\n",
        "\n",
        "    if log_y_axis:\n",
        "        plt.yscale('log')\n",
        "\n",
        "    plt.xticks(ticks=np.arange(0, num_iterations, step=max(1, num_iterations // 8)))\n",
        "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
        "    plt.legend(fancybox=True, handlelength=1.5, shadow=False, loc='best', ncol=1,\n",
        "               fontsize=36, framealpha=1.0, edgecolor='black', borderpad=0.4, borderaxespad=0.1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dipclorAkDrr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def run_experiments(num_runs, num_iterations, experiment, data_gen_func, base_seed=42, output=\"Error Plot\",\n",
        "                    y_lab=r\"\\text{Relative Error} $\\displaystyle\\frac{\\lVert \\tilde{D} - WH \\rVert}{\\lVert \\tilde{D} \\rVert}$\"):\n",
        "    \"\"\"\n",
        "    Runs multiple experiments and collects error values.\n",
        "\n",
        "    Parameters:\n",
        "        num_runs (int): Number of independent experimental runs.\n",
        "        num_iterations (int): Number of iterations per run.\n",
        "        experiments (dict): Dictionary mapping experiment labels to experiment specifications.\n",
        "            Each specification is a dict with the following (optional) keys:\n",
        "                - 'alg_func': (required) Function handle for the algorithm (e.g., StandardNMF or CorruptionRobustNMF).\n",
        "                - 'alg_params': (optional) Dictionary of additional parameters to pass to the algorithm.\n",
        "                - 'data_params': (optional) Dictionary of parameters to pass to the data generation function.\n",
        "                - 'data_input': (optional) Tuple (ref_choice, train_choice) where each element is either\n",
        "                                \"X\" (uncorrupted data) or \"X_corrupted\" (corrupted data). Default is (\"X\", \"X_corrupted\").\n",
        "                - 'model_rank': (optional) Target rank. If provided, it will be passed as the fourth argument.\n",
        "        data_gen_func (function): Function to generate data. It should accept keyword arguments (if any)\n",
        "                                  and return a tuple (X, X_corrupted).\n",
        "        base_seed (int): Base random seed for reproducibility.\n",
        "        output (set): Set of strings indicating what output to generate. Can be \"Error Plot\" or \"Swimmer Image\".\n",
        "\n",
        "    Returns:\n",
        "        results (dict): Dictionary mapping experiment labels to numpy arrays of error values with shape\n",
        "                        (num_runs, T), where T is the length of the error vector returned by the algorithm.\n",
        "    \"\"\"\n",
        "    results = {label: [] for label in experiment}\n",
        "    runtimes = {label: [] for label in experiment}\n",
        "    seed = base_seed\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        np.random.seed(seed)\n",
        "        for label, exp in experiment.items():\n",
        "            # Get data generation parameters (if any) and generate data.\n",
        "            data_params = exp.get('data_params', {})\n",
        "            D, D_tilde = data_gen_func(**data_params)\n",
        "\n",
        "            # Determine which data to use as reference and for training.\n",
        "            # data_input should be a tuple: (ref_choice, train_choice), each either \"X\" or \"X_corrupted\".\n",
        "            data_input = exp.get('data_input', (\"X\", \"X_corrupted\"))\n",
        "            D_ref = D_tilde if data_input[0] == \"D_tilde\" else D\n",
        "            D_train = D_tilde if data_input[1] == \"D_tilde\" else D\n",
        "\n",
        "            # Retrieve the algorithm function and any extra parameters.\n",
        "            alg_func = exp['alg_func']\n",
        "            alg_params = exp.get('alg_params', {})\n",
        "            model_rank = exp.get('model_rank', None)\n",
        "\n",
        "            # Run the algorithm. If model_rank is specified, pass it as the fourth argument.\n",
        "            outputs = alg_func(D_ref, D_train, num_iterations, model_rank, **alg_params)\n",
        "            # Assume that the error vector is the last output.\n",
        "            errors = outputs[-2]\n",
        "            results[label].append(errors)\n",
        "            runtime = outputs[-1]\n",
        "            runtimes[label].append(runtime)\n",
        "        seed += 1\n",
        "\n",
        "    # Convert list of error vectors to numpy arrays.\n",
        "    for label in results:\n",
        "        runtimes_of_label = [runtimes[label][trial] for trial in range(num_runs)]\n",
        "        print(f\"{label}: average runtime {round(np.mean(runtimes_of_label), 4)} +/- {round(np.std(runtimes_of_label), 4)} seconds\")\n",
        "\n",
        "        results[label] = np.array(results[label])\n",
        "\n",
        "    if output == \"Error Plot\":\n",
        "          plot_experiment(results, log_y_axis=True, y_lab=y_lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLztzfWIFFXy"
      },
      "source": [
        "## Synthetic Data\n",
        "\n",
        "In the following experiments, we generate synthetic data matrices by generating an exactly factorizable matrix $\\tilde{\\mathbf{D}} = \\hat{\\mathbf{W}}\\hat{\\mathbf{H}}$ where $\\hat{\\mathbf{W}} \\in \\mathbb{R}^{n_1 \\times \\hat{r}}$ and $\\hat{\\mathbf{H}} \\in \\mathbb{R}^{\\hat{r} \\times n_2}$ have integer entries sampled uniformly at random from $\\{0, \\cdots, 100\\}$. We then form the corrupted data $\\mathbf{D}$ by sampling entries uniformly at random from $\\tilde{\\mathbf{D}}$ and adding an element sampled from $|N(0,10^{12})|$. In all experiments, unless otherwise specified, we set the model rank equal to the rank of the uncorrupted data, $r = \\hat{r}$, and the predicted uncorrupted proportion (quantile) $q$ equal to the true uncorrupted proportion $1-\\beta$.  In each experiment that follows, we train each model for 400 iterations and run 10 trials with different factor matrix initializations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Hrsh5DyVjO"
      },
      "source": [
        "### Comparing standard multiplicative updates and QMU (Figure 2)\n",
        "\n",
        "In our first experiment, we compare the behavior of standard multiplicative updates and QMU applied to the uncorrupted synthetic data $\\tilde{\\mathbf{D}} \\in \\mathbb{R}^{120 \\times 100}$ with rank $\\hat{r} = 40$, and corrupted data $\\mathbf{D}$ with corruption rate $\\beta = 0.2$. We run standard multiplicative updates on corrupted data $\\mathbf{D}$ and uncorrupted data $\\tilde{\\mathbf{D}}$, as well as QMU on corrupted data $\\mathbf{D}$. %$\\tilde{\\mathbf{D}}$ and $\\mathbf{D}$ have dimensions $120 \\times 100$ with a data rank of 40, and we corrupt $20\\%$ of the entries in $\\tilde{\\mathbf{D}}$ to create $\\mathbf{D}$.\n",
        " All errors are measured against the uncorrupted data $\\tilde{\\mathbf{D}}$. The plot generated below demonstrates that although standard multiplicative updates with uncorrupted data reaches the lowest overall error, in the presence of large additive corrupted values, QMU vastly outperforms standard multiplicative updates. This illustrates how QMU ignores entries corresponding to large residual values and performs the update using only the other entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNExrfuNNWPF",
        "outputId": "d5a7a2aa-7b6f-4354-90be-add8ecc9e8ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard NMF on $\\tilde{D}$: average runtime 0.132 +/- 0.032 seconds\n",
            "Standard NMF on $D$: average runtime 0.1377 +/- 0.0348 seconds\n",
            "QMU on $D$: average runtime 0.2622 +/- 0.0892 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {\n",
        "    r\"Standard NMF on $\\tilde{D}$\": {\n",
        "        \"alg_func\": nmf,\n",
        "        \"alg_params\": {},\n",
        "        \"data_input\": (\"D_tilde\", \"D_tilde\"),  # Use uncorrupted data for both error measurement and training.\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40}\n",
        "    },\n",
        "    r\"Standard NMF on $D$\": {\n",
        "        \"alg_func\": nmf,\n",
        "        \"alg_params\": {},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),  # Measure error on X but train on corrupted X.\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.2}\n",
        "    },\n",
        "    r\"QMU on $D$\": {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.8},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.2}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R9iZUcRmMep"
      },
      "source": [
        "### Relative error against corrupted and uncorrupted data (Figure 3)\n",
        "\n",
        "In our second experiment, we compare the errors of the matrix factorization produced by QMU on $\\mathbf{D}$ with model rank $r = 40$ measured against uncorrupted data $\\tilde{\\mathbf{D}}\\in \\mathbb{R}^{120 \\times 100}$ with rank $\\hat{r} = 40$ and corrupted data $\\mathbf{D}$ with corruption rate $\\beta = 0.1$.\n",
        "\n",
        "The error plot generated below demonstrates that QMU does not fit to the corrupted data $\\mathbf{D}$ but instead fits to the uncorrupted data $\\tilde{\\mathbf{D}}$, despite not being provided this uncorrupted input, indicating it is able to identify and ignore the corrupted entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5j4eDj2hmMep"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU trained on $\\displaystyle D$ measured against $\\displaystyle \\tilde{D}$: average runtime 0.2574 +/- 0.0278 seconds\n",
            "QMU trained on $\\displaystyle D$ measured against $\\displaystyle D$: average runtime 0.2802 +/- 0.0842 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {\n",
        "    r\"QMU trained on $\\displaystyle D$ measured against $\\displaystyle \\tilde{D}$\": {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D_tilde\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.1}\n",
        "    },\n",
        "    r\"QMU trained on $\\displaystyle D$ measured against $\\displaystyle D$\": {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.1}\n",
        "    },\n",
        "}\n",
        "\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"}, y_lab=\"Relative Error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0AcWLEZjy0"
      },
      "source": [
        "### Varying quantile $q$ with fixed corruption rate $\\beta$ (Figure 4)\n",
        "\n",
        "In this experiment, we vary the quantile hyperparameter $q$ while holding the data corruption rate $\\beta$ constant at $\\beta = 0.2$. We once again generate uncorrupted data $\\tilde{\\mathbf{D}}\\in \\mathbb{R}^{120 \\times 100}$ with rank $\\hat{r} = 40$ and corrupted data $\\mathbf{D}$ with corruption rate $\\beta = 0.2$, and match the model rank $r=40$. The plot generated below illustrates that quantile $q = 0.8 = 1 - \\beta$ performs best, while when too many entries are masked ($1-q > \\beta$) the method performs slightly worse, and when we fail to mask the corruptions ($1-q < \\beta$) the method diverges. This result highlights the need to select a conservative quantile $q$; however, in real-world contexts, this may be challenging to determine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-THSKcKXruB",
        "outputId": "95823a59-732a-4904-fa15-271eb45a435f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.95$: average runtime 0.1987 +/- 0.0199 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.90$: average runtime 0.1977 +/- 0.0235 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.85$: average runtime 0.198 +/- 0.0223 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.80$: average runtime 0.2152 +/- 0.0169 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.75$: average runtime 0.1919 +/- 0.0141 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for q in [0.95, 0.9, 0.85, 0.8, 0.75]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle q = {q:.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": q},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.15}\n",
        "    }\n",
        "\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2iCzcgcExli"
      },
      "source": [
        "### Varying $\\beta$ with fixed $q$\n",
        "\n",
        "Similar to the previous experiment, in this experiment we measure the error when applying our method with fixed $q = 0.15$ and vary$\\beta$. We once again use matrix dimensions $120 \\times 100$ with true data rank $40$, and match the model rank to also be $r=40$. The plot generated below illustrates the error results. Consistent with the previous result, the model performs optimally for $1-q = \\beta$, slightly worse when $1-q > \\beta$, and significantly worse when $1-q < \\beta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "I9oIpisgGH8V",
        "outputId": "82cfd263-04b2-4765-c784-3daee658f362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.05$: average runtime 0.2051 +/- 0.0191 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.10$: average runtime 0.2044 +/- 0.0136 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.15$: average runtime 0.1982 +/- 0.0132 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.20$: average runtime 0.2004 +/- 0.0154 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.25$: average runtime 0.193 +/- 0.0191 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for beta in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle \\beta = {beta:.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.85},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),  # Use uncorrupted data for both error measurement and training.\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": beta}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9r0xlD3HEqE"
      },
      "source": [
        "### Varying corruption rate $\\beta$ and quantile $q$ together (Figure 5)\n",
        "\n",
        "In this experiment, we vary the quantile $q$ and the corruption rate $\\beta$ together such that $q + \\beta = 1$. We once again generate uncorrupted data $\\tilde{\\mathbf{D}}\\in \\mathbb{R}^{120 \\times 100}$ with rank $\\hat{r} = 40$, and match the model rank $r=40$. The plot generated below displays the training error of the different learned models for each combination tested of $q$ and $\\beta$. We observe that error increases as corruption rate $\\beta$ increases, however, this error increase is gradual as only slightly less information is available in each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "XjJjdywYHD9o",
        "outputId": "2b77eba7-8856-42e3-8cc8-d773311d2283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.05, q = 0.95$: average runtime 0.2064 +/- 0.013 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.10, q = 0.90$: average runtime 0.1962 +/- 0.0198 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.15, q = 0.85$: average runtime 0.2034 +/- 0.0223 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.20, q = 0.80$: average runtime 0.2009 +/- 0.0237 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.25, q = 0.75$: average runtime 0.1946 +/- 0.0102 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for beta in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle \\beta = {beta:.2f}, q = {(1 - beta):.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 1 - beta},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),  # Use uncorrupted data for both error measurement and training.\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": beta}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig71L1EOZsv_"
      },
      "source": [
        "### Varying model rank $r$ (Figure 6)\n",
        "\n",
        "In this experiment, we measure the effectiveness of QMU on corrupted synthetic data when varying the model rank $r$. We once again generate uncorrupted data $\\tilde{\\mathbf{D}}\\in \\mathbb{R}^{120 \\times 100}$ with rank $\\hat{r} = 40$ and corrupted data $\\mathbf{D}$ with corruption rate $\\beta = 0.1$. We run QMU on $\\mathbf{D}$ with model ranks $r \\in \\{10, 20, 40, 60\\}$ and measure error against $\\tilde{\\mathbf{D}}$. As shown in the error plot generated below, model performance suffers if we underestimate the rank of the data, but overestimating the rank does not result in a significant difference in performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "RzHwyeR7ZpZK",
        "outputId": "86f6490f-aca4-4655-e652-182dfdca22b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 4$: average runtime 0.1364 +/- 0.0141 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 8$: average runtime 0.1403 +/- 0.0176 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 16$: average runtime 0.1573 +/- 0.0078 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 32$: average runtime 0.1838 +/- 0.0184 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 64$: average runtime 0.2847 +/- 0.0183 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for r in [4, 8, 16, 32, 64]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle r = {r}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": r,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": 40, \"beta\": 0.1}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmVletVkEKSl"
      },
      "source": [
        "### Varying rank of the data\n",
        "\n",
        "In this experiment, we measure the effectiveness of QMU on corrupted synthetic data when varying the rank of the data. Matrices $\\tilde{\\mathbf{D}}$ are randomly generated with ranks of 16, 24, 32, and 40 and dimensions $64\\times 48$, and $10\\%$ of their entries, chosen at random, are corrupted to produce $\\mathbf{D}$. We run QMU on $\\mathbf{D}$ of each rank, with the algorithm assuming a rank of 32, for 400 iterations and repeat this experiment 10 times. All errors were measured against $\\tilde{\\mathbf{D}}$. As shown in The error plot generated below, the model performance does not depend too much on the rank of the data, although it does seem to perform better on $\\mathbf{D}$ with small rank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "ZcPvI5_7EKEA",
        "outputId": "faa95131-3507-4e61-f2d8-1fb9ccf167d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 4$: average runtime 0.1664 +/- 0.0121 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 8$: average runtime 0.1646 +/- 0.0098 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 16$: average runtime 0.163 +/- 0.0127 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 32$: average runtime 0.1643 +/- 0.0094 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 64$: average runtime 0.1638 +/- 0.0121 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for r in [4, 8, 16, 32, 64]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle r = {r}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": 16,\n",
        "        \"data_params\": {\"m\": 120, \"n\": 100, \"r\": r, \"beta\": 0.1}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJyTCkR5OIYI"
      },
      "source": [
        "### Different Matrix Dimensions\n",
        "\n",
        "In this experiment, we measure the effectiveness of QMU on corrupted data matrices generated with corruption rate $\\beta = 0.1$ from uncorrupted matrices with the same rank, $\\hat{r} = 20$, but different dimensions, $30 \\times 25$, $60 \\times 50$, $120\\times 100$ and $240 \\times 200$.\n",
        "%$10\\%$ of their entries, chosen at random, are corrupted to produce $\\mathbf{D}$.\n",
        "We run QMU on each $\\mathbf{D}$ with model rank $r = 20$. All errors are measured against $\\tilde{\\mathbf{D}}$. As shown in The error plot generated below, the model error does not depend strongly on the dimensions of the data matrices. However, the model does take more time per iteration for larger matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "aSaSVUwLONvb",
        "outputId": "8e8b13cf-6759-42c9-ed72-bcc4f0cd4442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with dimensions $\\displaystyle 16 \\times 12$: average runtime 0.0226 +/- 0.0016 seconds\n",
            "QMU on $\\displaystyle D$ with dimensions $\\displaystyle 32 \\times 24$: average runtime 0.0274 +/- 0.0019 seconds\n",
            "QMU on $\\displaystyle D$ with dimensions $\\displaystyle 64 \\times 48$: average runtime 0.045 +/- 0.0031 seconds\n",
            "QMU on $\\displaystyle D$ with dimensions $\\displaystyle 128 \\times 96$: average runtime 0.194 +/- 0.0085 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for m, n in [(16, 12), (32, 24), (64, 48), (128, 96)]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with dimensions $\\displaystyle {m} \\times {n}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": m // 4,\n",
        "        \"data_params\": {\"m\": m, \"n\": n, \"r\": m // 4, \"beta\": 0.1}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=generate_synthetic_matrix,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC17DTbDFWZ9"
      },
      "source": [
        "## Swimmer Data\n",
        "\n",
        "In this section, we apply the proposed method to a toy image dataset called the \\texttt{Swimmer} dataset, which is composed of $11 \\times 20$-pixel images.\n",
        "\n",
        "We let $\\tilde{\\mathbf{D}}$ be the matrix with columns that are the vectorized images from the \\texttt{Swimmer} dataset, and note that this matrix has data rank $\\hat{r} = 16$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ompGSOhOFWZ-"
      },
      "source": [
        "### Standard Multiplicative Updates vs. QMU (Figure 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "8hgRLD9tFWZ-",
        "outputId": "a990a397-cfd1-447e-8b06-d86f54021685"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "# Assume the following functions are defined elsewhere in your code:\n",
        "# load_swimmer_dataset, nmf, qmu\n",
        "\n",
        "# Load the dataset and compute matrices with NMF and QMU\n",
        "D, D_tilde = load_swimmer_dataset(beta=0.05, corruption_scale=5)\n",
        "\n",
        "W_nmf_uncorr, H_nmf_uncorr, _, _, _ = nmf(D_tilde, D_tilde, 400, 17, seed=42)\n",
        "W_nmf_corr, H_nmf_corr, _, _, _ = nmf(D_tilde, D, 400, 17, seed=42)\n",
        "W_qmu, H_qmu, _, _, _ = qmu(D_tilde, D, 400, 17, 0.95, seed=42)\n",
        "\n",
        "# Compute the five matrices of interest:\n",
        "mat_a = np.reshape(D_tilde[:, 17], (11, 20))\n",
        "mat_b = np.reshape((W_nmf_uncorr @ H_nmf_uncorr)[:, 17], (11, 20))\n",
        "mat_c = np.reshape(D[:, 17], (11, 20))\n",
        "mat_d = np.reshape((W_nmf_corr @ H_nmf_corr)[:, 17], (11, 20))\n",
        "mat_e = np.reshape((W_qmu @ H_qmu)[:, 17], (11, 20))\n",
        "\n",
        "# Set up a figure with 3 rows and 2 columns:\n",
        "fig = plt.figure(constrained_layout=True, figsize=(8, 10))\n",
        "gs = gridspec.GridSpec(3, 2, figure=fig)\n",
        "\n",
        "# Create subplots:\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "ax5 = fig.add_subplot(gs[2, :])  # Spans both columns\n",
        "\n",
        "# List of axes, corresponding matrices, and captions:\n",
        "axes = [ax1, ax2, ax3, ax4, ax5]\n",
        "matrices = [mat_a, mat_b, mat_c, mat_d, mat_e]\n",
        "captions = [r'(a) $\\tilde{D}$', r'(b) NMF on $\\tilde{D}$', r'(c) $D$', r'(d) NMF on $D$', r'(e) QMU on $D$']\n",
        "\n",
        "# Calculate the global minimum and maximum for a fixed color scale\n",
        "global_min = min(np.min(M) for M in matrices)\n",
        "global_max = max(np.max(M) for M in matrices)\n",
        "\n",
        "# Plot each matrix and add its caption:\n",
        "for ax, M, caption in zip(axes, matrices, captions):\n",
        "    ax.imshow(M, cmap='viridis', vmin=global_min, vmax=global_max)\n",
        "    ax.axis('off')  # Remove x and y axes\n",
        "    # Add a caption in the top-left corner of the axis\n",
        "    ax.text(0.05, 0.95, caption,\n",
        "            transform=ax.transAxes,\n",
        "            fontsize=14, fontweight='bold',\n",
        "            fontfamily='sans-serif',\n",
        "            color='white',\n",
        "            verticalalignment='top')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wRnXDTpFWZ-"
      },
      "source": [
        "### QMU Corrupted vs Uncorrupted Error Measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "5r3rF8gkFWZ-",
        "outputId": "4b66f0b8-a708-4431-c255-6fedd0dc7876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU trained on $\\displaystyle D$ measured against $\\displaystyle \\tilde{D}$: average runtime 0.8526 +/- 0.2096 seconds\n",
            "QMU trained on $\\displaystyle D$ measured against $\\displaystyle D$: average runtime 0.8929 +/- 0.2283 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {\n",
        "    r\"QMU trained on $\\displaystyle D$ measured against $\\displaystyle \\tilde{D}$\": {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D_tilde\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"beta\": 0.1}\n",
        "    },\n",
        "    r\"QMU trained on $\\displaystyle D$ measured against $\\displaystyle D$\": {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"beta\": 0.1}\n",
        "    },\n",
        "}\n",
        "\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=load_swimmer_dataset,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVGoqK-zFWZ-"
      },
      "source": [
        "### Different Guesses for $q$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "TOBf41SNFWZ-",
        "outputId": "768fca23-f3b8-4b86-a7f9-c2fec775c799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.95$: average runtime 1.5063 +/- 0.4196 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.90$: average runtime 2.3922 +/- 0.6818 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.85$: average runtime 1.0025 +/- 0.2407 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.80$: average runtime 0.9532 +/- 0.2096 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle q = 0.75$: average runtime 0.9007 +/- 0.3239 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for q in [0.95, 0.9, 0.85, 0.8, 0.75]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle q = {q:.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": q},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"beta\": 0.15}\n",
        "    }\n",
        "\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=load_swimmer_dataset,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMSdm5OOFWZ-"
      },
      "source": [
        "### Fixed $q$, varying $\\beta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "MHFO1oagFWZ-",
        "outputId": "70a930db-d811-436e-f33e-ccad59c73f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.05$: average runtime 1.0251 +/- 0.2193 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.10$: average runtime 1.038 +/- 0.3229 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.15$: average runtime 1.0056 +/- 0.214 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.20$: average runtime 2.8307 +/- 0.7787 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.25$: average runtime 1.6198 +/- 0.5723 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for beta in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle \\beta = {beta:.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.85},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"beta\": beta}\n",
        "    }\n",
        "\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=load_swimmer_dataset,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkMbduIgFWZ-"
      },
      "source": [
        "### Varying $q$ and $\\beta$ together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "I70K6xt5FWZ-",
        "outputId": "df87bc80-08c0-4c33-8bb8-5a7c7543bdab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.05, q = 0.95$: average runtime 0.6728 +/- 0.0277 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.10, q = 0.90$: average runtime 0.7014 +/- 0.0375 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.15, q = 0.85$: average runtime 0.703 +/- 0.0262 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.20, q = 0.80$: average runtime 0.725 +/- 0.0159 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle \\beta = 0.25, q = 0.75$: average runtime 0.7115 +/- 0.0233 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for beta in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle \\beta = {beta:.2f}, q = {(1 - beta):.2f}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 1 - beta},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),  # Use uncorrupted data for both error measurement and training.\n",
        "        \"model_rank\": 40,\n",
        "        \"data_params\": {\"beta\": beta}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=load_swimmer_dataset,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_GYKPtgFWZ-"
      },
      "source": [
        "### Different Model Ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "x7YNrryBFWZ-",
        "outputId": "4ceca273-177b-48a0-cd07-f23c0043febd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 4$: average runtime 0.4659 +/- 0.1863 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 8$: average runtime 0.4958 +/- 0.256 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 16$: average runtime 0.6718 +/- 0.1403 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 32$: average runtime 0.8491 +/- 0.2552 seconds\n",
            "QMU on $\\displaystyle D$ with $\\displaystyle r = 64$: average runtime 1.2533 +/- 0.4757 seconds\n"
          ]
        }
      ],
      "source": [
        "experiment = {}\n",
        "for r in [4, 8, 16, 32, 64]:\n",
        "    experiment[rf\"QMU on $\\displaystyle D$ with $\\displaystyle r = {r}$\"] = {\n",
        "        \"alg_func\": qmu,\n",
        "        \"alg_params\": {\"q\": 0.9},\n",
        "        \"data_input\": (\"D_tilde\", \"D\"),\n",
        "        \"model_rank\": r,\n",
        "        \"data_params\": {\"beta\": 0.1}\n",
        "    }\n",
        "\n",
        "# Run the experiments:\n",
        "run_experiments(num_runs=10, num_iterations=400,\n",
        "                          experiment=experiment, data_gen_func=load_swimmer_dataset,\n",
        "                          base_seed=42, output={\"Error Plot\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
